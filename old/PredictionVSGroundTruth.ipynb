{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Comparing ground truth with prediction 3D CNN\n",
    "\n",
    "This notebook analyses ground truth angles VS prediction angles for 3D CNN model.\n",
    "\n",
    "## Setup\n",
    "- Download and unpack training data\n",
    "- Create DonkeyCar project and load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# do we have the correct env loaded?\n",
    "assert 'donkey2' == os.environ['CONDA_DEFAULT_ENV'], os.environ['CONDA_DEFAULT_ENV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "![ ! -d \"mycar/\" ] && \\\n",
    "donkey createcar --path mycar && \\\n",
    "cp config/myconfig.py mycar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'donkeycar')\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Common settings for both directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________             ______                   _________              \n",
      "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
      "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
      "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
      "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
      "                                 /____/                              \n",
      "\n",
      "using donkey v4.3.5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 0 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config file: mycar/config.py\n",
      "loading personal config over-rides from myconfig.py\n"
     ]
    }
   ],
   "source": [
    "from dataloader import load_data\n",
    "import numpy as np\n",
    "import donkeycar as dk\n",
    "from donkeycar.parts import keras\n",
    "cfg = dk.load_config(config_path='mycar/config.py')\n",
    "\n",
    "# None means all the data is used.\n",
    "# use a smaller size, like 200 for testing end to end.\n",
    "TUBRECORD_SIZE = None\n",
    "\n",
    "SEQUENCE_LENGTH = 3\n",
    "cfg.SEQUENCE_LENGTH = SEQUENCE_LENGTH\n",
    "cfg.WANDB_ENABLED = False\n",
    "cfg.TRANSFORMATIONS = ['CROP']\n",
    "cfg.ROI_CROP_TOP = 60\n",
    "N_FOLDS = 5\n",
    "DATA_PATH = 'data'\n",
    "MODELS_PATH = 'models'\n",
    "\n",
    "MODEL_CLASS = keras.Keras3D_CNN_ModifiedOnlySteering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Load Counter Clockwise tubs and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import get_folds\n",
    "import itertools\n",
    "\n",
    "DIRECTION = 'CC'\n",
    "\n",
    "tub_records_80_speed, tub_records_85_speed, tub_records_90_speed = load_data(cfg, DATA_PATH, DIRECTION, TUBRECORD_SIZE)\n",
    "\n",
    "all_90_speed_data = list(itertools.chain(*list(tub_records_90_speed.values())))\n",
    "train_folds, test_folds = get_folds(all_90_speed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from losses import ModelResults\n",
    "\n",
    "CC_ModelResults = ModelResults(\n",
    "    MODEL_CLASS,\n",
    "    MODELS_PATH,\n",
    "    SEQUENCE_LENGTH,\n",
    "    DIRECTION,\n",
    "    N_FOLDS,\n",
    "    tub_records_80_speed,\n",
    "    tub_records_85_speed,\n",
    "    tub_records_90_speed,\n",
    "    train_folds,\n",
    "    test_folds,\n",
    "    cfg\n",
    ")\n",
    "\n",
    "CC_ModelResults.predict_results()\n",
    "\n",
    "CC_results = CC_ModelResults.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "def get_tub_predictions(results):\n",
    "    tub_ground_truths = {}\n",
    "    fold_tub_preds = defaultdict(list)\n",
    "    for fold, fold_results in results.items():\n",
    "        for speed_name, results in fold_results.items():\n",
    "            for res in results:\n",
    "                if res.name not in ['test90', 'train90']:\n",
    "                    tub_ground_truths[res.name] = res.ground_truths\n",
    "                    fold_tub_preds[res.name].append(res.predictions)\n",
    "\n",
    "    # NB! Taking the average over all 5 fold's predictions\n",
    "    tub_preds = OrderedDict({k: np.array(v).mean(axis=0) for k, v in sorted(fold_tub_preds.items(), key=lambda k:k[0][-2:], reverse=True)})\n",
    "    return tub_preds, tub_ground_truths\n",
    "\n",
    "CC_tub_preds, CC_tub_ground_truths = get_tub_predictions(CC_results)\n",
    "len(CC_tub_preds), len(CC_tub_ground_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot Counter Clockwise tubs predictions and ground truths\n",
    "\n",
    "NB:\n",
    "1. Graphs need to be read from down-up direction - the start of the recording is in the bottom of the graph.\n",
    "2. The .9-speed tubs have all the data in it. No train-test split is used here, the 90-speed tubs predictions are better than test and probably worse than train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_gt_and_pred(tub_preds, tub_ground_truths):\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(30, 250), sharex='all', sharey='all')\n",
    "    for (name, preds), ax in zip(tub_preds.items(), axs.flat):\n",
    "        ax.set(title=name, ylabel='frame number', xlabel='angle')\n",
    "        ax.grid(True, axis='x')\n",
    "\n",
    "        gt = tub_ground_truths[name]\n",
    "        ax.plot(gt, range(len(gt)), 'b', label='ground truth')\n",
    "\n",
    "        ax.plot(preds, range(len(preds)), 'g:', label='prediction')\n",
    "        ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_gt_and_pred(CC_tub_preds, CC_tub_ground_truths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Thoughts\n",
    "1. In these plots and even more so in the \"EDA1\" notebook, it can be seen that the number of laps vary greatly over different tubs and speeds. The 0.9 speed tubs contain more laps. Maybe we should calculate the mse-s for each tub/speed with each having an equal number of laps - maybe more laps is causing a higher error?\n",
    "2. Slower speeds (0.8) tend to slow down quite a lot during the end of the recording. When calculating losses, these parts should be removed to get a more accurate error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load Clockwise tubs and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from losses import ModelResults\n",
    "\n",
    "DIRECTION = 'CW'\n",
    "\n",
    "\n",
    "tub_records_80_speed, tub_records_85_speed, tub_records_90_speed = load_data(cfg, DATA_PATH, DIRECTION, TUBRECORD_SIZE)\n",
    "\n",
    "all_90_speed_data = list(itertools.chain(*list(tub_records_90_speed.values())))\n",
    "train_folds, test_folds = get_folds(all_90_speed_data)\n",
    "\n",
    "CW_ModelResults = ModelResults(\n",
    "    MODEL_CLASS,\n",
    "    MODELS_PATH,\n",
    "    SEQUENCE_LENGTH,\n",
    "    DIRECTION,\n",
    "    N_FOLDS,\n",
    "    tub_records_80_speed,\n",
    "    tub_records_85_speed,\n",
    "    tub_records_90_speed,\n",
    "    train_folds,\n",
    "    test_folds,\n",
    "    cfg\n",
    ")\n",
    "\n",
    "CW_ModelResults.predict_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CW_results = CW_ModelResults.results\n",
    "\n",
    "CW_tub_preds, CW_tub_ground_truths = get_tub_predictions(CW_results)\n",
    "len(CW_tub_preds), len(CW_tub_ground_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot Clockwise tubs predictions and ground truths\n",
    "\n",
    "NB:\n",
    "1. Graphs need to be read from down-up direction - the start of the recording is in the bottom of the graph.\n",
    "2. The .9-speed tubs have all the data in it. No train-test split is used here, the 90-speed tubs predictions are better than test and probably worse than train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_gt_and_pred(CW_tub_preds, CW_tub_ground_truths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Difference VS prediction and ground truth\n",
    "Plot one tub's difference (prediction - ground truth) and it's predictions and ground truths graph side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tub_diffs = defaultdict(list)\n",
    "for fold, fold_results in CW_results.items():\n",
    "    for speed_name, results in fold_results.items():\n",
    "        for res in results:\n",
    "            if res.name not in ['test90', 'train90']:\n",
    "                tub_diffs[res.name].append(res.predictions - res.ground_truths)\n",
    "\n",
    "tub_diffs = {k: np.array(v).mean(axis=0) for k,v in tub_diffs.items()}\n",
    "len(tub_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tub_name = '2-1-CW-80'\n",
    "tub_diffs[tub_name].shape, CW_tub_preds[tub_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [30/2.54, 25/2.54]\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(30, 100), sharex='all', sharey='all')\n",
    "\n",
    "ax1 = axs.flat[0]\n",
    "ax1.set(title=tub_name + ' prediction - ground truth', ylabel='frame number', xlabel='angle')\n",
    "ax1.grid(visible=True, which='both')\n",
    "ax1.plot(tub_diffs[tub_name], range(len(tub_diffs[tub_name])), label='prediction - ground truth')\n",
    "\n",
    "ax2 = axs.flat[1]\n",
    "ax2.set(title=tub_name + ' predictions and ground truths', ylabel='frame number', xlabel='angle')\n",
    "ax2.grid(visible=True, which='both')\n",
    "ax2.plot(CW_tub_preds[tub_name], range(len(CW_tub_preds[tub_name])), 'g:', label='prediction')\n",
    "gt = CW_tub_ground_truths[tub_name]\n",
    "ax2.plot(gt, range(len(gt)), 'b', label='ground truth')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Thoughts\n",
    "The difference graph is quite difficult to compare with the predictions-ground truths graphs. Maybe it is not correct to get the predictions from the 5 models and average over folds? It may make sense to train one model on all .9 speed data and look at it's predictions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donkey2",
   "language": "python",
   "name": "donkey2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}